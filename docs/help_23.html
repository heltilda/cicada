<HTML>

<HEAD>
<TITLE>Cicada Help: Writing and debugging a Cicada wrapper</TITLE>

<a href="https://heltilda.github.io/cicada/index.html">Cicada</a> ---> <a href="https://heltilda.github.io/cicada/toc.html">Online Help Docs</a> ---> <a href="https://heltilda.github.io/cicada/help_2.html">Example:  memory networks in Cicada</a>

<H1> <CENTER> Writing and debugging a Cicada wrapper </CENTER> </H1>
</HEAD>

<BODY>



<P> Once inside Cicada, we can run our neural network C function by typing

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &gt; $runNetwork(...)

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P>  The main danger here is that we might pass the wrong datatypes, or arrays of the wrong sizes, into our C code, which will then promptly crash.  To do things properly, let&rsquo;s write a Cicada class that stores the neural network data and provides methods for initializing, running and training the network.

<P> This will be a learning exercise.  It&rsquo;s our first time scripting so there will probably be a few bugs.<P>

<P>  <u>NN.cicada</u>

<P> 

<P><P><tt> 

<br> neural_network :: {

<br> &nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;numNeurons :: int

<br> &nbsp;&nbsp;&nbsp;numInputs :: numOutputs :: numHiddens

<br> &nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;weights :: [][] double

<br> &nbsp;&nbsp;&nbsp;activity :: [] double

<br> &nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;init :: {

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if trap( { numInputs, numOutputs, numHiddens } = args ) /= passed&nbsp;then (

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(&quot;usage:&nbsp;myNN.init(inputs, outputs, hidden neurons)\n&quot;)

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numNeurons = numInputs + numOutputs + numHiddens + 1

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activity[^numNeurons]

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weights[^numNeurons][^numNeurons]

<br> &nbsp;&nbsp;&nbsp;}

<br> &nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;process :: {

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numArgs :: rtrn :: int

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;step_size :: learning_rate :: double

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inputs :: outputs :: [] double

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inputs[^1] = 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// the 'bias' input

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;code

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numArgs = top(args)

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if trap(

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inputs[^numInputs + 1]

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inputs[&lt;2, numInputs+1&gt;] = args[1][]

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if numArgs == 4&nbsp;then (

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputs[^numOutputs]

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputs[&lt;1, numOutputs&gt;] = args[2][]

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{ step_size, learning_rate } = { args[3], args[4] }&nbsp;)

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else if numArgs == 2&nbsp;then &amp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;step_size = args[2]

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else&nbsp;throw(1)

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;) /= passed&nbsp;then (

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(&quot;usage:&nbsp;myNN.process(input, step_size OR &quot;,

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;input, target output, step_size, learning_rate)\n&quot;)

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if numArgs == 2&nbsp;then &amp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rtrn = $runNetwork(weights, activity, inputs, step_size)

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else &amp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rtrn = $runNetwork(weights, activity, inputs, step_size, outputs, learning_rate)

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if rtrn == 1&nbsp;then print(&quot;process() did not converge; try lowering step size?\n&quot;)

<br> &nbsp;&nbsp;&nbsp;}

<br> &nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;

<br> &nbsp;&nbsp;&nbsp;init(0, 0, 0)

<br> }

<br> </tt>

<P>

<P>  Save <tt>NN.cicada</tt> in the same directory as our NN program.  Then, from Cicada&rsquo;s command prompt, let&rsquo;s try out our new wrapper by typing:

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &gt; run(&quot;NN&quot;)

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; Error:&nbsp;left-hand argument expected in file NN

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; 29:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inputs[^1] = 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// the 'bias' input

<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;^

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P> What we see here is a &lsquo;compile-time&rsquo; error (i.e. it failed to produce bytecode).  Evidently we wrote a C-style comment &lsquo;<tt>//</tt>&rsquo; in place of a Cicada comment &lsquo;<tt>|</tt>&rsquo;.  Make the straightforward fix to <tt>NN.cicada</tt>.

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inputs[1] = 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| the 'bias' input

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P>  and try again.

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &gt; run(&quot;NN&quot;)

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; Error:&nbsp;member 'numHiddens' not found in file NN

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; 4:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numInputs :: numOutputs :: numHiddens

<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;^

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P>  This is progress: at least <tt>NN.cicada</tt> is syntactically correct.  Line 4 tried to define <tt>numInputs</tt> and <tt>numOutputs</tt> to be of type <tt>numHiddens</tt>, rather than defining all three variables as type <tt>int</tt>, so let&rsquo;s fix that:

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;numInputs :: numOutputs :: numHiddens :: int

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P>  and re-run our script.

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &gt; run(&quot;NN&quot;)

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; usage:&nbsp;myNN.init(inputs, outputs, hidden neurons)

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P> This time the script successfully &lsquo;compiled&rsquo; and ran.. although <tt>init()</tt> produced an odd usage message despite never having been run.  But at least a <tt>neural_network</tt> object was constructed, so we can start looking around inside, using the command prompt as a sort of debugger.  <tt>init()</tt> is suspicious so let&rsquo;s see if it works when we do run it.

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &gt; neural_network.init(3, 4, 5)

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; &gt;

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P>  So far so good(?).  There should now be 13 neurons in our network (including the &lsquo;bias&rsquo; neuron).

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &gt; neural_network.activity

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; {&nbsp;}

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P>  So something is definitely wrong.  To take a better look around, let&rsquo;s &lsquo;go&rsquo; inside our network.

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &gt; go(neural_network)

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; &gt; weights

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; {&nbsp;}

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; &gt; numNeurons

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; 0

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; &gt; go()

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P>  The last line takes us back to our &lsquo;root&rsquo; workspace.

<P> So our <tt>init()</tt> call was a dud -- nothing happened.  Our next step might be to put a trace statement in the coding section of the <tt>init()</tt> function.. hmm, wherever that is..  Looks like we forgot a <tt>code</tt> marker separating the function variables from its executable code, which fully explains why it won&rsquo;t run.  The <tt>init()</tt> method should begin:

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;init :: {

<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;code

<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if trap( { numInputs, numOutputs, numHiddens } = args ) /= passed&nbsp;then (

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P>  Making that final change, let&rsquo;s go back and try

<P> 

<P><P><tt> 

<br>&nbsp;&nbsp;&nbsp; &gt; run(&quot;NN&quot;), neural_network.init(3, 4, 5)

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; &gt; neural_network.activity

<br>&nbsp;&nbsp;&nbsp; 

<br>&nbsp;&nbsp;&nbsp; { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }

<br>&nbsp;&nbsp;&nbsp; </tt>

<P>

<P>  Finally we see what we were hoping for:  an array of neurons, initialized to a resting state and ready to begin training.

<P> <ul>
</ul><br><P><div align="center"><a href="https://heltilda.github.io/cicada/help_22.html">Prev: Putting the C in Cicada</a> &nbsp;&nbsp;
<a href="https://heltilda.github.io/cicada/help_24.html">Next: The Anagrambler</a>
</div><br><br><P>Last update: November 12, 2025